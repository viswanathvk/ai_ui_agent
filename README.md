ğŸ§  Real-Time UI Capture Agent

This project automates real-time user interface (UI) state capture across live web applications. Itâ€™s designed as part of a multi-agent automation system where an AI agent observes, reasons, and acts on web UIs â€” capturing each step of the workflow for downstream analysis or training data generation.

ğŸš€ Overview

The Real-Time UI Capture Agent:

Navigates live web applications (e.g., Notion, Linear, Jira, etc.)

Identifies UI elements dynamically, even when they lack fixed names or IDs

Captures screenshots of each meaningful UI state in the workflow

Uses a reasoning model to decide the next action (click, type, wait, etc.)

Stores all captured states (DOM + images) for replay, debugging, or model training

ğŸ§© Architecture
â”œâ”€â”€ main.py             # Entry point to run the agent
â”œâ”€â”€ browser.py          # Handles Playwright browser automation
â”œâ”€â”€ reasoning.py        # AI reasoning module to decide next action
â”œâ”€â”€ save_state.py       # Reuses saved login sessions
â”œâ”€â”€ screenshots/        # Folder for captured UI screenshots
â””â”€â”€ requirements.txt    # Project dependencies

âš™ï¸ How It Works

Goal Input â€“ The user defines a goal (e.g., â€œCreate a new project in Linearâ€).

Browser Launch â€“ The system opens the target web app using Playwright.

Reasoning Loop â€“ For each state:

Extracts DOM text and takes a screenshot

Passes data to the reasoning model (local or API)

Executes the modelâ€™s chosen action (click/type/etc.)

Capture Output â€“ Each UI step is saved as an image + JSON description.

ğŸ§  Reasoning Model

The reasoning logic can run on:

OpenAI GPT models (e.g., gpt-4-turbo)

Local open-source models via Ollama (e.g., llava, moondream, llama3.2-vision)

Example prompt structure:

- action: [click | type | wait | done]
- target: [element label or placeholder]
- value: [if typing, what text]
- reasoning: [why this step was chosen]

ğŸª„ Setup Instructions
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Save your login sessions
python save_state.py

3ï¸âƒ£ Run the agent
python main.py

4ï¸âƒ£ View captured screenshots

All captured steps will appear in the screenshots/ folder.

ğŸ’¡ Example Use Case

Goal: â€œHow do I create a project in Linear?â€
The agent will:

Load Linear dashboard

Locate â€œCreate projectâ€ button

Fill in fields and submit

Capture screenshots of each step

Stop when success state is detected

ğŸ§° Tech Stack

Python 3.10+

Playwright â€“ browser automation

OpenAI / Ollama â€“ reasoning models

PIL / OpenCV â€“ optional image processing

ğŸ§± Future Enhancements

âœ… DOM element detection with visual bounding boxes

âœ… Integration with LLaVA or GPT-Vision for UI comprehension

ğŸ”œ Action replay & workflow reconstruction

ğŸ”œ Fine-tuning dataset for RPA and reasoning models

ğŸ§‘â€ğŸ’» Author

Viswa Kasturi
Building intelligent agents that think and act on live UIs.
